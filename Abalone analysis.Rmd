---
title: "final"
output: html_document
date: "2023-05-01"
editor_options: 
  chunk_output_type: console
---

```{r}
library(readr)
library(GGally)
library(car)
library(glmnet)
library(caret)
library(Metrics)
library(gvlma)
library(rsq)
library(readr)
library(readr)
library(MVA)
library(pROC)
library(HSAUR2)
library(SciViews)
library(scatterplot3d)
library(car)
library(lattice)
library(GGally)
library(caTools)
library(ggplot2)
library(ggridges)
library(ggvis)
library(ggcorrplot)
library(ggthemes)
library(cowplot)
library(gapminder)
library(gganimate)
library(dplyr)
library(tidyverse)
library(grid)
library(gridExtra)
library(RColorBrewer)
library(Hotelling)
library(stats)
library(biotools)
library(factoextra)
library(FactoMineR)
library(ggfortify)
library(psych)
library(cluster)
library(corrplot)
library(caret)
library(MASS)
library(ggplot2)
library(memisc)
library(ROCR)
library(dplyr)
library(klaR)
library(readxl)
```


```{r}
abalone <- read_excel("~/Documents/Courses/Multivariate Analysis/Final/Final_MVA_2023.xlsx")
summary(abalone)
abalone$Age <- abalone$Rings + 1.5
View(abalone)
colSums(is.na(abalone))
```

Creating dummy vars for gender

```{r}
dummy_df <- dummyVars("~ Gender", data = abalone)

# Apply the dummy variables to the original data frame
transformed_df <- predict(dummy_df, newdata = abalone[1])

# View the transformed data frame
#head(transformed_df)

df <- cbind(abalone, transformed_df)
df = df[, -1]
View(df)
```

Correlation plot

```{r}
ggpairs(data=df, title="Abalone")
```

What attributes proved valuable in predicting the age?
1. Shell weight
2. Height
3. Diameter
These values are the most valuable for predicting age.
There is also rings with a 1.00 correlation because it is just rings + 1.5 so that does not count.

Taking log of the data as the data is non linear in nature

```{r}
ablog <- abalone
# Take the log of the dataset
ablog$Length <- log(ablog$Length)
ablog$Diameter <- log(ablog$Diameter)
ablog$Height <- log(ablog$Height)
ablog$`Whole Weight` <- log(ablog$`Whole Weight`)
ablog$`Shucked Weight` <- log(ablog$`Shucked Weight`)
ablog$`Viscera weight` <- log(ablog$`Viscera weight`)
ablog$`Shell weight` <- log(ablog$`Shell weight`)
ablog$Age <- log(ablog$Age)
ablog$Rings <- log(ablog$Rings)
summary(ablog)
colSums(is.na(ablog))

dummy_df_log <- dummyVars("~ Gender", data = ablog)

# Apply the dummy variables to the original data frame
transformed_df_log <- predict(dummy_df_log, newdata = ablog[1])

# View the transformed data frame
head(transformed_df_log)

df_log <- cbind(ablog, transformed_df_log)
ggpairs(data=df_log, aes(colour = Gender, alpha = 0.8), title="Pairs plot for abalone dataset") + 
  theme_grey(base_size = 8)
df_log = df_log[, -1]

```

Train test split

```{r}
set.seed(42) # set a seed value for reproducibility
trainIndexlog <- createDataPartition(df_log$Rings, p = 0.7, list = FALSE)
trainDatalog <- df_log[trainIndexlog, ]
testDatalog <- df_log[-trainIndexlog, ]
```


```{r}
abalone.reg.log <- lm(Rings~Length + Diameter + Height + `Whole Weight` + `Shucked Weight` + `Viscera weight` + `Shell weight` + GenderF + GenderM, data=trainDatalog)
summary(abalone.reg.log)
predictionslog <- predict(abalone.reg.log, newdata=testDatalog)
RMSE(predictionslog, testDatalog[, 8])
y_pred <- exp(predictionslog)
y_actual <- exp(testDatalog[, 8])
ape <- abs((y_actual - y_pred) / y_actual) * 100
mape <- mean(ape, na.rm = TRUE)
cat("MAPE:", round(mape, 2), "%")
plot(abalone.reg.log, which = 1)
plot(abalone.reg.log, which = 2) #Normal Q-Q PLOT

hist(abalone.reg.log$residuals)
```


Accuracy of the model (MAPE) is 15.03%
This accuracy is lower because I have taken log transformation of the entire dataset since it was non linear
The model is not a perfect normal disttribution. 
residual vs fitted plot shows some pattern in the data, as the residuals are increasing as the fitted values are increasing.
The qq plot has a tail which indicates that there are some errors.
there is scope to improve this model.

> Logistic Regression 

```{r}
ggpairs(data=abalone, aes(colour = Gender, alpha = 0.8), title="Pairs plot for abalone dataset") + 
  theme_grey(base_size = 8)
```

Train test split

```{r}
set.seed(42) # set a seed value for reproducibility
abalone$Sex_binary <- ifelse(abalone$Gender == "M", 1, 0)
abalone$Sex_binary <- as.factor(abalone$Sex_binary)
train_index1 <- sample(1:nrow(abalone), nrow(abalone)*0.7)
train_data1 <- abalone[train_index1, ]
test_data1 <- abalone[-train_index1, ]
```

Model

```{r}
logit_model <- glm(Sex_binary ~ Length + Diameter + Height + `Whole Weight` + `Shucked Weight` + `Viscera weight` + `Shell weight` + Rings, data=train_data1, family=binomial)
```

Predict

```{r}
test_data1$predicted_sex <- predict(logit_model, newdata=test_data1, type="response")
test_data1$predicted_sex_binary <- ifelse(test_data1$predicted_sex > 0.5, 1, 0)
```

Evaluate model

```{r}
confusionMatrix(as.factor(test_data1$predicted_sex_binary), test_data1$Sex_binary)
precision(test_data1$predicted_sex_binary, test_data1$Sex_binary)
recall(test_data1$predicted_sex_binary, test_data1$Sex_binary)
roc <- roc(test_data1$Gender, test_data1$predicted_sex_binary)
plot(roc, main = "ROC curve", print.auc = TRUE)
```

The confusion matrix shows that the model predicted 142 cases as 0 and the actual value was also 0. The model predicted 127 cases as 1, but the actual value was 0. The model predicted 251 cases as 0, but the actual value was 1. Finally, the model predicted 331 cases as 1, and the actual value was also 1.


The accuracy is 55.58% of the logistic regression model.
Sensitivity : 0.3613          
Specificity : 0.7227   
AUC: 0.54
We can predict the gender but it is barely better than a coin flip.

```{r}
# Build an LDA model
lda_model <- lda(Sex_binary ~ . - Sex_binary, data = train_data1[, 2:11])

# Check the model summary
summary(lda_model)

# Make predictions on the test set
lda_pred <- predict(lda_model, newdata = test_data1[, 2:11])
lda_pred <- lda_pred$class

# Calculate accuracy measures
table(lda_pred, test_data1$Sex_binary)
acc <- sum(lda_pred == test_data1$Sex_binary)/length(test_data1$Sex_binary)
acc
```

The accuracy is 55.93%
It is barely better than the logistic regression model.

> Logistic regression using PCA

```{r}
pca <- prcomp(abalone[,2:9],scale=TRUE)
summary(pca)
```


### Scree diagram

```{r}
fviz_eig(pca, addlabels = TRUE)
```

I am choosing 3 PC components after looking at the scree plot.

```{r}
pca <- as.data.frame(pca$x)
pca <- pca[1:3]

pca$Gender <- abalone$Sex_binary
```

Train test split

```{r}
set.seed(42) # set a seed value for reproducibility
train_index2 <- sample(1:nrow(pca), nrow(pca)*0.7)
train_data2 <- pca[train_index2, ]
test_data2 <- pca[-train_index2, ]
```

Model

```{r}
logit_model2 <- glm(Gender ~ PC1 + PC2 + PC3, data=train_data2, family=binomial)
```

Predict

```{r}
test_data2$predicted_sex <- predict(logit_model2, newdata=test_data2, type="response")

test_data2$predicted_sex_binary <- ifelse(test_data2$predicted_sex > 0.5, 1, 0)
```

Evaluate model

```{r}
confusionMatrix(as.factor(test_data2$predicted_sex_binary), test_data2$Gender)

precision(test_data2$predicted_sex_binary, test_data2$Gender)
recall(test_data2$predicted_sex_binary, test_data2$Gender)
roc1 <- roc(test_data2$Gender, test_data2$predicted_sex_binary)
plot(roc1, main = "ROC curve", print.auc = TRUE)
```

We are getting worse accuracy with PCA. 

> Logistic Regression using FA

```{r}
fit.pc <- principal(abalone[, 2:9], nfactors=4, rotate="varimax")
fit.pc
round(fit.pc$values, 3)
fit.pc$loadings
# Loadings with more digits
for (i in c(1,3,2,4)) { print(fit.pc$loadings[[1,i]])}
# Communalities
fit.pc$communality
# Rotated factor scores, Notice the columns ordering: RC1, RC3, RC2 and RC4
# Play with FA utilities
fa.parallel(abalone[, 2:9]) # See factor recommendation
fa.plot(fit.pc) # See Correlations within Factors
fa.diagram(fit.pc) # Visualize the relationship
vss(abalone[, 2:9]) # See Factor recommendations for a simple structure

fit.pc <- as.data.frame(fit.pc$scores)
fit.pc <- fit.pc[1:2]

fit.pc$Gender <- abalone$Sex_binary
fit.pc$Rings <- abalone$Rings
```

Train test split

```{r}
set.seed(42) # set a seed value for reproducibility
train_index3 <- sample(1:nrow(fit.pc), nrow(fit.pc)*0.7)
train_data3 <- fit.pc[train_index3, ]
test_data3 <- fit.pc[-train_index3, ]
```

Model

```{r}
logit_model3 <- glm(Gender ~ RC1 + RC3, data=train_data3, family=binomial)
```

Predict

```{r}
test_data3$predicted_sex <- predict(logit_model3, newdata=test_data3, type="response")

test_data3$predicted_sex_binary <- ifelse(test_data3$predicted_sex > 0.5, 1, 0)
```

Evaluate model

```{r}
confusionMatrix(as.factor(test_data3$predicted_sex_binary), test_data3$Gender)

precision(test_data3$predicted_sex_binary, test_data3$Gender)
recall(test_data3$predicted_sex_binary, test_data3$Gender)
roc2 <- roc(test_data3$Gender, test_data3$predicted_sex_binary)
plot(roc2, main = "ROC curve", print.auc = TRUE)
```

FA also does not give us promising results for logistic regression to predict gender.
Dimentionality reduction techniques did not make the classification model better.
PCA and FA both failed to perform.

> 1. Linear regression model is decent with a MAPE accuracy of 15%.
The residual analysis shows that there are discernable patterns in the data even after taking a log transformation of the dataset. the qq plot shows that there is a tail indicating that it does not follow a perfect normal distribution.

> Attributes proved valuable in predicting the age are:
> 1. Shell weight
> 2. Height
> 3. Diameter
There is also rings with a 1.00 correlation because it is just rings + 1.5 so that does not count.

>2. The MAPE accuracy on the Rings column is 15%.
>3. We can predict the gender but it is barely better than a coin flip.
I have used various accuracy measures like AUC, ROC and confusion matrix.
> Logistic regression accuracy: 55.58%
> LDA: 55.93%

>4. No, it dimention reduction does not improve our accuracy.
PCA: 53.35%
FA: 53.11%